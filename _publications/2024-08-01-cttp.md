---
title: "Contrastive Touch-to-Touch Pretraining (CTTP)"
collection: publications
permalink: /publication/2024-08-01-cctp
excerpt: 'We present a contrastive self-supervised learning method to unify tactile feedback across different sensors, using paired tactile data. By treating paired signals as positives and unpaired ones as negatives, our approach learns a sensor-agnostic latent representation, capturing shared information without relying on reconstruction or task-specific supervision.'
date: 2024-08-01
venue: 'Under Review'
image: "/images/projects/cttp.png"
paperurl: 'https://arxiv.org/abs/2410.11834v1'
website: 'https://www.mmintlab.com/research/cttp/'
authors: 'Samanta Rodriguez, Yiming Dou, William van den Bogert, <b>Miquel Oller</b>, Kevin So, Andrew Owens, Nima Fazeli'
citation: "{{ authors }} &quot;{{ title }}&quot;.<i> {{venue}} {{ date | date: '%Y' }}</i>."
videourl: 'https://www.mmintlab.com/wp-content/uploads/2024/09/cttp_paper_video.mp4'
---


<img src="{{ page.image }}" alt="{{ page.title }}" style="border-radius: 20px;">

Tactile sensors differ greatly in design, making it challenging to develop general-purpose methods for processing tactile feedback. In this paper, we introduce a contrastive self-supervised learning approach that represents tactile feedback across different sensor types. Our method utilizes paired tactile data—where two distinct sensors, in our case Soft Bubbles and GelSlims, grasp the same object in the same configuration—to learn a unified latent representation. Unlike current approaches that focus on reconstruction or task-specific supervision, our method employs contrastive learning to create a latent space that captures shared information between sensors. By treating paired tactile signals as positives and unpaired signals as negatives, we show that our model effectively learns a rich, sensor-agnostic representation. Despite significant differences between Soft Bubble and GelSlim sensors, the learned representation enables strong downstream task performance, including zero-shot classification and pose estimation. This work provides a scalable solution for integrating tactile data across diverse sensor modalities, advancing the development of generalizable tactile representations.

<!-- VIDEO -->
{% if page.videourl %}
    {% include video.html videourl=page.videourl %}
{% endif %}
{% if page.videoid %}
    {% include youtube.html videoid=page.videoid %}
{% endif %}


Project website: [{{ page.title }}]({{ page.website }})


[Download paper here]({{page.paperurl}})
